# Final Report Experiment Ideas:

## Train different models:

1. What happens when the agent is trained to ignore future rewards (low discount factor)?
2. What happens when we focus on exploitation over exploration (changes in epsilon and decay)?
3. Is the model at least significantly better over taking random actions?
4. How does it perform in other games? // Optional if we have time!

## Conclusions

